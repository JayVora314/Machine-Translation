{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_test_phase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sle_V44oZCJ"
      },
      "source": [
        "**Note that to run this notebook, you have to upload hindistatements.csv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndCtAwhD0H-U"
      },
      "source": [
        "#The pipeline used is :\n",
        "\n",
        "\n",
        "1.   Importing data\n",
        "2.   Preprocessing data by tokenizing it and converting it to tensor\n",
        "3.   Defining the model Architecture\n",
        "4.   Running SGD on the model\n",
        "5.   Evaluating on the test data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7H8PMPCRWWP"
      },
      "source": [
        "#Importing all the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeXUGwpHA3tk"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import csv\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUYfip4Si0XJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793ac490-20cc-4030-ef7c-ca0988a3be33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbpY4Wini3E1"
      },
      "source": [
        "# Getting the training dataset file from gdrive\n",
        "!unzip -o ./drive/MyDrive/train.zip >> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gPfMm9YA5GB",
        "outputId": "6cf926a4-b241-41ef-858e-2ef84c7312fa"
      },
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\"\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!pip install Morfessor\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1271, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1271 (delta 50), reused 54 (delta 25), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1271/1271), 9.56 MiB | 16.20 MiB/s, done.\n",
            "Resolving deltas: 100% (654/654), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 41.64 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Collecting Morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_559ek4k6DU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKXnHl4UBT-g"
      },
      "source": [
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
        "\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "\n",
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sz3UBeNpJvT"
      },
      "source": [
        "#Importing the nltk library to tokenize english sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8prsx_3BVoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227695c6-67e1-4e71-cd72-76640e45aec0"
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "import nltk\n",
        "nltk.download('popular',quiet = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAfpMbzNlPZE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnkjCcIBRndE"
      },
      "source": [
        "#Defining the Start of Sentence and End of Sentence token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scPZcq9IBZIC"
      },
      "source": [
        "SOS = 0\n",
        "EOS = 1\n",
        "MAX_LENGTH = 598"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dLSAPbERyIN"
      },
      "source": [
        "#Importing data and converting to numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdIFToN2yyKj"
      },
      "source": [
        "datalines = []\n",
        "with open(\"train.csv\", 'r') as dfile:\n",
        "    datareader = csv.reader(dfile)\n",
        "\n",
        "    for row in datareader:\n",
        "        datalines.append(row)\n",
        "    \n",
        "hindi_sents = [l[1] for l in datalines[1::]]           #getting hindi sentences\n",
        "english_sents = [l[2] for l in datalines[1::]]         #getting english sentences\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqCGazpc14Kq",
        "outputId": "e2b06fe0-f19c-4b89-f444-831504ec57d7"
      },
      "source": [
        "type(hindi_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq-t_70hBirG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz2iAgXsR5N-"
      },
      "source": [
        "#Function to tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr0hCz58Bn7E"
      },
      "source": [
        "def tokenize(data,lang):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "      data : imported dataset from train.csv\n",
        "      lang : 'hi' or 'eng'\n",
        "\n",
        "  Output:\n",
        "      dataset : dictionary containing all the necessary information like word frequency count, indexing dictionary,tokenized sentences etc.\n",
        "\n",
        "  \"\"\"\n",
        "  if lang =='hi':\n",
        "    hindi_sents = data\n",
        "    hindi_id = 2\n",
        "    hindi_words_freq = {}\n",
        "    hindi_to_id = {}\n",
        "    id_to_hindi = {0: \"SOS\", 1: \"EOS\"}\n",
        "    hindi_sen_token = []\n",
        "    hindi_token_all = []\n",
        "    for hindi_sen in hindi_sents:\n",
        "      hindi_sen_token = indic_tokenize.trivial_tokenize(hindi_sen)\n",
        "      hindi_token_all.append(hindi_sen_token)\n",
        "      for token in hindi_sen_token :\n",
        "        if token not in hindi_words_freq.keys() : \n",
        "          hindi_to_id[token] = hindi_id\n",
        "          id_to_hindi[hindi_id] = token\n",
        "          hindi_id = hindi_id + 1\n",
        "          hindi_words_freq[token] = 1\n",
        "        else:\n",
        "          hindi_words_freq[token] = hindi_words_freq[token] + 1\n",
        "\n",
        "    dataset = {\n",
        "    'hindi_vocab': hindi_words_freq, \n",
        "    'hindi_to_id': hindi_to_id, \n",
        "    'id_to_hindi': id_to_hindi, \n",
        "    'hindi_token_all': hindi_token_all}      \n",
        "\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  elif lang =='eng':\n",
        "    english_sents = data\n",
        "    english_id = 2\n",
        "    english_words_freq = {}\n",
        "    english_to_id = {}\n",
        "    id_to_english = {0: \"SOS\", 1: \"EOS\"}\n",
        "    english_sen_token = []\n",
        "    english_token_all = []\n",
        "    for english_sent in english_sents:\n",
        "      english_sen_token = nltk.word_tokenize(english_sent)\n",
        "      english_token_all.append(english_sen_token)\n",
        "      for token in english_sen_token :\n",
        "        if token not in english_words_freq.keys() : \n",
        "          english_to_id[token] = english_id\n",
        "          id_to_english[english_id] = token\n",
        "          english_id = english_id + 1\n",
        "          english_words_freq[token] = 1\n",
        "        else:\n",
        "          english_words_freq[token] = english_words_freq[token] + 1 \n",
        "\n",
        "    dataset = {\n",
        "    'english_vocab': english_words_freq, \n",
        "    'english_to_id': english_to_id, \n",
        "    'id_to_english': id_to_english, \n",
        "    'english_token_all': english_token_all}\n",
        "      \n",
        "\n",
        "      \n",
        "      #english_sents_id = torch.tensor(english_sents_id)    \n",
        "\n",
        "    return dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOBvdWtJSwuc"
      },
      "source": [
        "##Calling the tokenize function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRrdGSSmCMv7"
      },
      "source": [
        "hindi_data = tokenize(hindi_sents,'hi')\n",
        "english_data = tokenize(english_sents,'eng')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk4ReOoqCQMa"
      },
      "source": [
        "def get_embedding(hindi_token_sent,english_token_sent):\n",
        "  \"\"\"\n",
        "  Returns the vector embedding for the hindi and english sentence\n",
        "  Input:\n",
        "      hindi_token_sent : tokenized hindi sentence\n",
        "      english_token_sent : tokenized english sentence\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  hindi_index_sent = []\n",
        "  hindi_to_id = hindi_data['hindi_to_id'] \n",
        "  for word in hindi_token_sent:\n",
        "        if word not in hindi_to_id.keys():\n",
        "            hindi_index_sent.append(2)\n",
        "        else: \n",
        "            hindi_index_sent.append(hindi_to_id[word])\n",
        "\n",
        "  hindi_index_sent.append(EOS)  #Appending the EOS token\n",
        "  hindi_index_tensor = torch.tensor(hindi_index_sent, dtype=torch.long, device=device).view(-1, 1) # Converting to tensor\n",
        "\n",
        "  english_index_sent = []\n",
        "  english_to_id = english_data['english_to_id'] \n",
        "  for word in english_token_sent:\n",
        "        if word not in english_to_id.keys():\n",
        "            english_index_sent.append(2)\n",
        "        else: \n",
        "            english_index_sent.append(english_to_id[word])\n",
        "\n",
        "  english_index_sent.append(EOS)\n",
        "  english_index_tensor = torch.tensor(english_index_sent, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "  return (hindi_index_tensor,english_index_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6WVpimVCYuk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXk4lf_mVWTj"
      },
      "source": [
        "#Defining the Encoder with GRU unit, it also defines the embedding of input data used in the Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euLaMvnZCc-m"
      },
      "source": [
        "class EncoderModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderModel, self).__init__()\n",
        "        \n",
        "        # Setting Class Variables:\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        # Setting Layers:\n",
        "        self.EMB = nn.Embedding(input_size, hidden_size)\n",
        "        self.RNN = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, h_t):\n",
        "        x_embedding = self.EMB(x).view(1, 1, -1)\n",
        "        output, h_t = self.RNN(x_embedding, h_t)\n",
        "        return output, h_t\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbacw3YtVb2Q"
      },
      "source": [
        "#Defining the Attention Decoder with GRU units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMjvFTgfCj-W"
      },
      "source": [
        "class AttnDecoderModel(torch.nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p, max_length):\n",
        "        super(AttnDecoderModel, self).__init__()\n",
        "        \n",
        "        # Setting Class Variables:\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Setting Layers:\n",
        "        self.EM_LOOKUP = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.ATTENTION = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.A_COMBINE = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.L_DROPOUT = nn.Dropout(self.dropout_p)\n",
        "        self.RECURRENT = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        \n",
        "        context = self.EM_LOOKUP(input).view(1, 1, -1)\n",
        "        context = self.L_DROPOUT(context)\n",
        "\n",
        "        # Attention Mechanism:\n",
        "        attention_weights = torch.nn.functional.softmax(\n",
        "            input = self.ATTENTION(\n",
        "                torch.cat([context[0], hidden[0]], 1)\n",
        "            ), \n",
        "            dim = 1\n",
        "        )\n",
        "        \n",
        "        # print(attention_weights.unsqueeze(0).shape)\n",
        "        # print(encoder_outputs.unsqueeze(0).shape)\n",
        "\n",
        "        attention_weights = torch.bmm(\n",
        "            attention_weights.unsqueeze(0),\n",
        "            encoder_outputs.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        output = torch.cat(\n",
        "            tensors = (context[0], attention_weights[0]), \n",
        "            dim = 1\n",
        "        )\n",
        "        \n",
        "        output = self.A_COMBINE(output).unsqueeze(0)\n",
        "        output = torch.nn.functional.relu(output)\n",
        "        \n",
        "        output, hidden = self.RECURRENT(output, hidden)\n",
        "        \n",
        "        output = torch.nn.functional.log_softmax(\n",
        "            input = self.out(output[0]), \n",
        "            dim = 1\n",
        "        )\n",
        "\n",
        "        return output, hidden, attention_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DJ57nyoV0H0"
      },
      "source": [
        "#Forward pass through the model with teacher forcing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfqDAHWZC_Cx"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def forward_pass(input_tensor, target_tensor, encoder, decoder, encoder_opt, decoder_opt, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_opt.zero_grad()\n",
        "    decoder_opt.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)          #Length of input sentence\n",
        "    target_length = target_tensor.size(0)        #Length of target sentence\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS]], device=device)   #Adding start of sentence to the decoder input to be used in teacher forcing\n",
        "\n",
        "    \n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    #decoder_hidden = encoder_hidden\n",
        "    \n",
        "    if random.random() < teacher_forcing_ratio:\n",
        "      use_teacher_forcing = True\n",
        "    else:\n",
        "      use_teacher_forcing = False  \n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_opt.step()\n",
        "    decoder_opt.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ8KWz7oWArG"
      },
      "source": [
        "#Creating pairs of hindi_tensor and english_tensor for SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_eOOA0DMLVa",
        "outputId": "7e74e2e8-0d81-435a-d658-e4cb79f30a37"
      },
      "source": [
        "pairs = []\n",
        "hindi_tokens = hindi_data['hindi_token_all']\n",
        "english_tokens = english_data['english_token_all']\n",
        "print(len(hindi_tokens))\n",
        "print(len(english_tokens))\n",
        "for i in range(len(hindi_tokens)):\n",
        "  temp = get_embedding(hindi_tokens[i],english_tokens[i])\n",
        "  pairs.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102322\n",
            "102322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FbWjcbyWfPu"
      },
      "source": [
        "#Stochastic Gradient Descent which iterates through one example at a time compute loss,back_prop and then update parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGLE_vn0DJcG"
      },
      "source": [
        "def SGD(encoder, decoder,encoder_opt,decoder_opt, num_epochs, print_every=5000, learning_rate=0.01):\n",
        "\n",
        "  \"\"\"\n",
        "  encoder_opt = The optimizer of encoder\n",
        "  decoder_opt  = The optimizer of decoder\n",
        "  num_epcohs = Number of iterations through whole dataset\n",
        "  \"\"\"\n",
        "  start = time.time()\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  num_sents = len(hindi_data['hindi_token_all'])\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    choices = np.random.permutation(range(num_sents))   #Taking one random example at a time\n",
        "\n",
        "    step = 0\n",
        "\n",
        "    for i in choices:\n",
        " \n",
        "      english_s = convert_to_tensor(english_data['english_token_all'][i],'en')       #Converting the sentence to tensor\n",
        "      hindi_s = convert_to_tensor(hindi_data['hindi_token_all'][i],'hi')\n",
        "\n",
        "      loss = forward_pass(hindi_s, english_s, encoder, decoder, encoder_opt, decoder_opt, criterion)\n",
        "\n",
        "      step = step + 1\n",
        "\n",
        "      if step%100 ==0:\n",
        "\n",
        "        print(f'Epoch Number: {epoch + 1}, {step}/{num_sents} processed')\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1okC_7t-MhE9"
      },
      "source": [
        "def convert_to_tensor(sent,lang):\n",
        "  \"\"\"\n",
        "  Convert a sentence to a tensor, similar to get_embedding\n",
        "  \"\"\"\n",
        "  index_sent = []\n",
        "  if lang =='hi':\n",
        "    hindi_to_id = hindi_data['hindi_to_id'] \n",
        "    for word in sent:\n",
        "          if word not in hindi_to_id.keys():\n",
        "              index_sent.append(2)\n",
        "          else: \n",
        "              index_sent.append(hindi_to_id[word])\n",
        "\n",
        "    index_sent.append(EOS)\n",
        "    index_tensor = torch.tensor(index_sent, dtype=torch.long, device=device).view(-1, 1)\n",
        "    return index_tensor\n",
        "\n",
        "  if lang =='en':\n",
        "    english_to_id = english_data['english_to_id'] \n",
        "    for word in sent:\n",
        "          if word not in english_to_id.keys():\n",
        "              index_sent.append(2)\n",
        "          else: \n",
        "             index_sent.append(english_to_id[word])\n",
        "\n",
        "    index_sent.append(EOS)\n",
        "    index_tensor = torch.tensor(index_sent, dtype=torch.long, device=device).view(-1, 1)\n",
        "    return index_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3d3ARJIXPyc"
      },
      "source": [
        "#Function to evaluate on the test cases, similar to forward_pass. It also converts the tensor to sentence for better representation of output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5GIHbBIMULW"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length = MAX_LENGTH):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        input_tensor = convert_to_tensor(\n",
        "            indic_tokenize.trivial_tokenize(sentence), \n",
        "            'hi'\n",
        "        ).to(device)\n",
        "\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[0]], device=device) # init of sentence\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == 1:\n",
        "                decoded_words.append('__<<stop>>__')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(english_data['id_to_english'][topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLBbzGqIXd8y"
      },
      "source": [
        "#The SGD optimizer for the encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qfVPl-7Mtgt"
      },
      "source": [
        "def optimize(hidden_size,hindi_data,english_data):\n",
        "  \n",
        "  # Defining the encoder, decoder and their optimizers\n",
        "\n",
        "  encoder1 = EncoderModel(len(hindi_data['id_to_hindi']), hidden_size).to(device)\n",
        "  attn_decoder1 = AttnDecoderModel(hidden_size, len(english_data['id_to_english']), dropout_p=0.1,max_length=MAX_LENGTH).to(device)\n",
        "  encoder_opt = optim.SGD(encoder1.parameters(), lr=0.01)\n",
        "  decoder_opt = optim.SGD(attn_decoder1.parameters(), lr=0.01)\n",
        "  if trained == False:\n",
        "\n",
        "    #Running SGD on the above optimizers\n",
        "    SGD(encoder1,attn_decoder1, encoder_opt, decoder_opt, num_epochs = 20)  \n",
        "  \n",
        "  else :\n",
        "    encoder1.load_state_dict(torch.load('drive/MyDrive/trained_model/encoder.zip'))    \n",
        "    attn_decoder1.load_state_dict(torch.load('drive/MyDrive/trained_model/decoder.zip'))\n",
        "\n",
        "    encoder_opt.load_state_dict(torch.load('drive/MyDrive/trained_model/enc_optimizer.zip'))\n",
        "    decoder_opt.load_state_dict(torch.load('drive/MyDrive/trained_model/dec_optimizer.zip'))   \n",
        "  \n",
        "\n",
        "  return encoder1,attn_decoder1  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0cFoqHlCJOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf59011-f11d-436f-f941-975945563b90"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  8 05:13:41 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlABJL2qXouj"
      },
      "source": [
        "#Calling the optimizer to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jsTjD9yZ5OY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0VKnUzPs9ma"
      },
      "source": [
        "hidden_size = 512\n",
        "trained = True\n",
        "encoder1,attn_decoder1 = optimize(hidden_size,hindi_data,english_data)\n",
        "\n",
        "\n",
        "#Ran for 15 epochs to get the result\n",
        "#A local copy of the trained model is saved in my google drive\n",
        "\n",
        "#Ran it again to check if its functioning correctly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glPe766FAaH5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnDqMHNDAlIc"
      },
      "source": [
        "Saving the weights in drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwmlMSyWAaLO"
      },
      "source": [
        "save_weights = False\n",
        "\n",
        "if save_weights == True:\n",
        "    torch.save(encoder1.state_dict(), 'drive/MyDrive/_encoder')\n",
        "    torch.save(attn_decoder1.state_dict(), 'drive/MyDrive/_decoder')\n",
        "    torch.save(encoder_opt.state_dict(), 'drive/MyDrive/_enc_optimizer')\n",
        "    torch.save(decoder_opt.state_dict(), 'drive/MyDrive/_dec_optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3R9SIZlN2M1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "71a2f3a4-8261-4a41-f374-ba253dbd853b"
      },
      "source": [
        "#Evaluate the test dataset\n",
        "testlines = []\n",
        "with open(\"testhindistatements.csv\", 'r') as testfile:\n",
        "    testreader = csv.reader(testfile)  #Reading each line \n",
        "\n",
        "    for row in testreader:\n",
        "        testlines.append(row)\n",
        "\n",
        "inputs = [l[2] for l in testlines[1:]]\n",
        "\n",
        "outfile = open(\"answer.txt\", 'w+')       \n",
        "\n",
        "for i in range(len(inputs)):\n",
        "    output_words = evaluate(encoder1, attn_decoder1, inputs[i],max_length = MAX_LENGTH)        #Evaluating each line and saving in \"answer.txt\"\n",
        "    output_sentence = ' '.join(output_words[:-1])\n",
        "    \n",
        "    \n",
        "    outfile.write(output_sentence + \"\\n\")\n",
        "\n",
        "\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-25e52d59d010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutput_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#Evaluating each line and saving in \"answer.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-330b69490667>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m---> 29\u001b[0;31m                 decoder_input, decoder_hidden, encoder_outputs)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-252792e8b56a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRECURRENT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         output = torch.nn.functional.log_softmax(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfUIkSiQVLQv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
